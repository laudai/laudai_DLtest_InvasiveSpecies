{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work plan\n",
    "1. Download data\n",
    "1. Organize data into folders\n",
    "1. Finetune vgg model\n",
    "1. Train model\n",
    "1. Run predictions\n",
    "1. Evaluate predictions\n",
    "1. Submit to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "Done offline with Kaggle command line utility in Terminal ssh session. Unzip files.\n",
    "\n",
    "Confirmed below\n",
    "\n",
    "[Download_link](https://www.kaggle.com/c/invasive-species-monitoring/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize data into folders\n",
    "only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent file shortcuts\n",
    "import os, sys\n",
    "current_directory = os.getcwd()\n",
    "UTIL_DIR = '/home/laudai/AnacondaProjects/laudai_DLtest/utils'\n",
    "LESSON_HOME_DIR = current_directory\n",
    "DATA_HOME_DIR = current_directory+'/data/invasive_species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set path variables\n",
    "sys.path.insert(1, LESSON_HOME_DIR)\n",
    "sys.path.insert(1, UTIL_DIR)\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '..',\n",
       " '/home/laudai/AnacondaProjects/laudai_DLtest/utils',\n",
       " '/home/laudai/AnacondaProjects/laudai_DLtest',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python27.zip',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/plat-linux2',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/lib-tk',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/lib-old',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/lib-dynload',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/PIL',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg',\n",
       " '/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/home/laudai/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import utility modules\n",
    "from utils import *\n",
    "#plotting in jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\r\n",
      "Keras (1.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep Keras\n",
    "#laudai list Keras version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make directories\n",
    "#make your directories have data dir\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "%mkdir -p data/invasive_species/train/invasive\n",
    "%mkdir -p data/invasive_species/train/harmless\n",
    "%mkdir -p data/invasive_species/valid/invasive\n",
    "%mkdir -p data/invasive_species/valid/harmless\n",
    "%mkdir -p data/invasive_species/test/unknown\n",
    "%mkdir -p data/invasive_species/sample/train/invasive\n",
    "%mkdir -p data/invasive_species/sample/train/harmless\n",
    "%mkdir -p data/invasive_species/sample/valid/invasive\n",
    "%mkdir -p data/invasive_species/sample/valid/harmless\n",
    "%mkdir -p data/invasive_species/results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laudai/AnacondaProjects/laudai_DLtest/data/invasive_species/train\n",
      "ls: 無法存取 '*.jpg': 沒有此一檔案或目錄\n",
      "\n",
      "train_labels.csv\n",
      "name,invasive\n",
      "1,0\n",
      "2,0\n",
      "3,1\n",
      "4,0\n"
     ]
    }
   ],
   "source": [
    "#confirm training data & csv file with labels correctly loaded\n",
    "#downloaded and unpacked in terminal. \n",
    "\n",
    "%cd $DATA_HOME_DIR/train\n",
    "%ls *.jpg | head -5\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\ntrain_labels.csv\")\n",
    "!head -5 train_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '0'], ['2', '0'], ['3', '1'], ['4', '0'], ['5', '1']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to move images with '1' label into invasive folder and those with '0' to harmless folder\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "reader = csv.reader(open(\"train_labels.csv\", \"rb\"), delimiter=\",\")\n",
    "labels = list(reader)\n",
    "del labels[0]\n",
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm labels for all training data. 2295 from contest page.\n",
    "len(labels) == 2295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if you run first , u should run this block\n",
    "\"\"\"\n",
    "for l in labels:\n",
    "    iname = l[0] + \".jpg\"\n",
    "    if l[1] == '0':\n",
    "        !mv -t harmless/ $iname\n",
    "    elif l[1]== '1':\n",
    "        !mv -t invasive/ $iname\n",
    "\n",
    "\"\"\"\n",
    "#run once to move image stroge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mharmless\u001b[0m/  \u001b[01;34minvasive\u001b[0m/  train_labels.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laudai/AnacondaProjects/laudai_DLtest/data/invasive_species\n",
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mresults\u001b[00m\r\n",
      "│   ├── \u001b[01;34m54231_filenames.dat\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\r\n",
      "│   ├── \u001b[01;34m54231_preds.dat\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\r\n",
      "│   ├── \u001b[01;34m54242_filenames.dat\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│   │   └── \u001b[01;34mmeta\u001b[00m\r\n",
      "│   └── \u001b[01;34m54242_preds.dat\u001b[00m\r\n",
      "│       ├── \u001b[01;34mdata\u001b[00m\r\n",
      "│       └── \u001b[01;34mmeta\u001b[00m\r\n",
      "├── \u001b[01;34msample\u001b[00m\r\n",
      "│   ├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   │   ├── \u001b[01;34mharmless\u001b[00m\r\n",
      "│   │   └── \u001b[01;34minvasive\u001b[00m\r\n",
      "│   └── \u001b[01;34mvalid\u001b[00m\r\n",
      "│       ├── \u001b[01;34mharmless\u001b[00m\r\n",
      "│       └── \u001b[01;34minvasive\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   └── \u001b[01;34munknown\u001b[00m\r\n",
      "├── \u001b[01;34mtrain\u001b[00m\r\n",
      "│   ├── \u001b[01;34mharmless\u001b[00m\r\n",
      "│   └── \u001b[01;34minvasive\u001b[00m\r\n",
      "└── \u001b[01;34mvalid\u001b[00m\r\n",
      "    ├── \u001b[01;34mharmless\u001b[00m\r\n",
      "    └── \u001b[01;34minvasive\u001b[00m\r\n",
      "\r\n",
      "28 directories\r\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "!tree -d\n",
    "\n",
    "\n",
    "#!pwd\n",
    "#laudai\n",
    "#if you don't have use apt-get install tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laudai/AnacondaProjects/laudai_DLtest/data/invasive_species\n",
      "harmless  invasive  train_labels.csv\n",
      "763\n",
      "1057\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "#%cd $DATA_HOME_DIR\n",
    "!ls train/\n",
    "!ls train/harmless | wc -l\n",
    "!ls train/invasive/ | wc -l\n",
    "# to dispaly file count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#make validation files\n",
    "val_percentage = 0.1\n",
    "\n",
    "\n",
    "#laudai add\n",
    "%cd $DATA_HOME_DIR\n",
    "#num_validations = int(2295/2 * val_percentage)\n",
    "# I think this way is wrong\n",
    "\n",
    "#os.rename(src, dst)\n",
    "#Randomly permute a sequence, or return a permuted range.\n",
    "#laudai you should chagne harmless to ./train/harmless\n",
    "# laudai i don't have any idea with is this in \"train\" dict or in \"test\" dict?\n",
    "%cd ./train/harmless/\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "harmless_num_validations=int(len(shuf)*val_percentage)\n",
    "\n",
    "for i in range(harmless_num_validations): os.rename(shuf[i], DATA_HOME_DIR+'/valid/harmless/' + shuf[i])\n",
    "\n",
    "%cd ../invasive/\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "invasive_num_validations=int(len(shuf)*val_percentage)\n",
    "for i in range(invasive_num_validations): os.rename(shuf[i], DATA_HOME_DIR+'/valid/invasive/' + shuf[i])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "################\n",
    "val_percentage = 0.1\n",
    "#num_validations = int(2295/2 * val_percentage)\n",
    "# I think this way is wrong\n",
    "\n",
    "\n",
    "#os.rename(src, dst)\n",
    "#Randomly permute a sequence, or return a permuted range.\n",
    "#laudai you should chagne harmless to ./train/harmless\n",
    "# laudai i don't have any idea with is this in \"train\" dict or in \"test\" dict?\n",
    "%cd $DATA_HOME_DIR\n",
    "%cd ./train/harmless/\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "print len(shuf)\n",
    "harmless_num_validations=int(len(shuf)*val_percentage)\n",
    "print harmless_num_validations\n",
    "\n",
    "print len(shuf)\n",
    "%cd ../invasive/\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "print len(shuf)\n",
    "\n",
    "invasive_num_validations=int(len(shuf)*val_percentage)\n",
    "print invasive_num_validations\n",
    "#test use block\n",
    "##############"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Copy the file src to the file or directory dst. \n",
    "#If dst is a directory, a file with the same basename as src is created (or overwritten) in the directory specified. \n",
    "#Permission bits are copied. src and dst are path names given as strings.\n",
    "\n",
    "#make sample files\n",
    "from shutil import copy\n",
    "%cd $DATA_HOME_DIR\n",
    "num = 10\n",
    "for img in os.listdir('train/invasive/')[:num]: copy('train/invasive/'+ img, 'sample/train/invasive/')\n",
    "for img in os.listdir('train/harmless/')[:num]: copy('train/harmless/'+ img, 'sample/train/harmless/')\n",
    "for img in os.listdir('valid/invasive/')[:num]: copy('valid/invasive/'+ img, 'sample/valid/invasive/')\n",
    "for img in os.listdir('valid/harmless/')[:num]: copy('valid/harmless/'+ img, 'sample/valid/harmless/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune vgg model\n",
    "using vgg16.py file from fast.ai course. Model pre-trained on Imagenet. \n",
    "\n",
    "See https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more file shortcuts\n",
    "\n",
    "#Set path to /sample for development speed\n",
    "# path = DATA_HOME_DIR + '/sample'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DATA_HOME_DIR = \"/home/laudai/AnacondaProjects/laudai_DLtest/data/invasive_species\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "path = DATA_HOME_DIR\n",
    "test_path = DATA_HOME_DIR + '/test/' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '/results/'\n",
    "train_path=path + '/train/'\n",
    "valid_path=path + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/laudai/AnacondaProjects/laudai_DLtest/data/invasive_species/train/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_labels.csv', 'invasive', 'harmless']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train_path\n",
    "os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#instantiate pretrained model\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1820 images belonging to 2 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x7f0b3d378610>\n"
     ]
    }
   ],
   "source": [
    "#finetune model with our data\n",
    "batches = vgg.get_batches(train_path)\n",
    "#laudai\n",
    "\n",
    "\n",
    "# In this you will get problem , shutdown this project right now to toggle another project\n",
    "print batches\n",
    "vgg.finetune(batches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解決無法使用 l1 l2 activity_l1 activity_l2的方法\n",
    "#### 就是到github 上去找有沒有哪個版本是有這個的方法，再去灌這個版本 最後使用keras1.2.2\n",
    "[github 版本位置連結](https://github.com/fchollet/keras/blob/1.2.2/keras/regularizers.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set attributes\n",
    "num_epochs = 4\n",
    "lr = 0.001\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1820 images belonging to 2 classes.\n",
      "Found 475 images belonging to 2 classes.\n",
      "\n",
      "running epoch 0\n",
      "Epoch 1/1\n",
      "  40/1820 [..............................] - ETA: 4029s - loss: 0.9443 - acc: 0.6500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ac28aad622ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nrunning epoch %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlatest_weights_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_vgg_%d.h5'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlatest_weights_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/AnacondaProjects/laudai_DLtest/vgg16.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, batches, val_batches, nb_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         self.model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n\u001b[0;32m--> 213\u001b[0;31m                 validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1556\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_batches = vgg.get_batches(train_path)\n",
    "valid_batches = vgg.get_batches(valid_path)\n",
    "ts = str(int(time.time()))[-5:]\n",
    "latest_weights_filename = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"\\nrunning epoch %d\" % epoch)\n",
    "    vgg.fit(train_batches, valid_batches)\n",
    "    latest_weights_filename = ts + '_vgg_%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path + latest_weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "Evaluate some images to check our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#latest_weights_filename ='77272_vgg_4.h5'\n",
    "latest_weights_filename ='69904_vgg_3.h5'\n",
    "#use your vgg.h5 (PATH in RESULT dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load weights and generate predictions of validation set for review\n",
    "vgg.model.load_weights(results_path + latest_weights_filename)\n",
    "valid_batches, valid_preds = vgg.test(valid_path)\n",
    "valid_filenames = valid_batches.filenames\n",
    "expected_labels = valid_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#round off predictions to 0 or 1 to make labels\n",
    "s = valid_preds[:5]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#second column is probability of invasive\n",
    "s[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_predictions = valid_preds[:,1]\n",
    "#our_string_predictions = np.asarray([\"%.2f\" % p for p in our_predictions], dtype='|S9') #for titles- not working\n",
    "our_labels = np.round(our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles):\n",
    "    plots([image.load_img(valid_path + valid_filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correctly labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selected at random\n",
    "correct = np.where(our_labels == expected_labels)[0]\n",
    "print(\"found %d correct labels\" % len(correct))\n",
    "idx = np.random.permutation(correct)\n",
    "titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless', 'invasive')\n",
    "plots_idx(idx[:n_view], titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(correct)\n",
    "titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless', 'invasive')\n",
    "plots_idx(idx[:n_view], titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(correct)\n",
    "titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless', 'invasive')\n",
    "plots_idx(idx[:n_view], titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrectly labeled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selected at random\n",
    "incorrect = np.where(our_labels != expected_labels)[0]\n",
    "print(\"found %d incorrect labels\" % len(incorrect))\n",
    "idx = np.random.permutation(incorrect)\n",
    "titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless:', 'invasive')\n",
    "plots_idx(idx[:n_view], titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(incorrect)\n",
    "titles = np.where(our_labels[idx[:n_view]] == 0.0, 'harmless:', 'invasive')\n",
    "plots_idx(idx[:n_view], titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images with highest uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain[:n_view]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confustion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)\n",
    "plot_confusion_matrix(cm, valid_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 822, in next\n",
      "    index_array, current_index, current_batch_size = next(self.index_generator)\n",
      "  File \"/home/laudai/anaconda2/envs/python27_DL/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 645, in _flow_index\n",
      "    current_index = (self.batch_index * batch_size) % n\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preds is a numpy array of predictions\n",
    "\n",
    "\n",
    "test_batches, preds = vgg.test(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save predictions\n",
    "filenames = test_batches.filenames\n",
    "ts = str(int(time.time()))[-5:]\n",
    "save_array(results_path + ts + '_preds.dat', preds)\n",
    "save_array(results_path + ts + '_filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "evals = 10\n",
    "image_display_size = 512, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9dd531414a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testfile %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtestfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_display_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "testfile = 0\n",
    "print(\"testfile %d\" % testfile + np.array_str(preds[testfile]))\n",
    "im = Image.open(test_path + filenames[testfile])\n",
    "im.resize(image_display_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle\n",
    "Create file then submit offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson1/data/invasive_species/results\n"
     ]
    }
   ],
   "source": [
    "%cd $results_path\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])\n",
    "is_invasive = preds[:,1]\n",
    "submission = np.stack((ids, is_invasive), axis = 1)\n",
    "filename = \"kevin\" + ts + \".csv\"\n",
    "np.savetxt(filename, submission, fmt=\"%d,%.5f\", header='name,invasive', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
